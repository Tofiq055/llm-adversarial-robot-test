# ğŸš€ HÄ±zlÄ± Kurulum Rehberi (Docker Mimarisi)

Bu rehber, **Grup A** (A4 Adversarial Test ve A2 Safety Supervisor) projeleri iÃ§in sisteminizi hazÄ±rlar.

**DÄ°KKAT:** Proje host (yerel) bilgisayar Ã¼zerinde DEÄÄ°L, tamamen izole Docker konteynerleri iÃ§inde Ã§alÄ±ÅŸacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.

## Gereksinimler

| BileÅŸen | Minimum |
|---|---|
| OS | Ubuntu 22.04 LTS |
| GPU | NVIDIA (driver kurulu olmalÄ±) |
| RAM | 8 GB+ (16 GB Ã¶nerilir) |
| Disk | 30 GB boÅŸ alan |

> [!important]
> **RTX 3060 KÄ±sÄ±tlamasÄ±**: Sistemin aynÄ± anda hem 3D simÃ¼lasyon modelini (Gazebo) oluÅŸturmasÄ± hem de Yerel YZ modelini (Ollama) GPU Ã¼zerinde tutabilmesi iÃ§in VRAM'in (6GB) dikkatli kullanÄ±lmasÄ± gerekir.

---

## Kurulum AdÄ±mlarÄ±

### 1. Host HazÄ±rlÄ±ÄŸÄ± (Sadece 1 Kere)

Ä°ÅŸletim sisteminizde sadece **NVIDIA sÃ¼rÃ¼cÃ¼sÃ¼**, **Docker** ve **NVIDIA Container Toolkit** olmasÄ± yeterlidir. BunlarÄ± kurmak iÃ§in:

```bash
# Repo'yu klonla
git clone https://github.com/Tofiq055/llm-adversarial-robot-test.git
cd llm-adversarial-robot-test

# Host hazÄ±rlÄ±k betiÄŸini Ã§alÄ±ÅŸtÄ±r
bash setup_host.sh
```

*(EÄŸer betik `newgrp docker` veya oturumu kapatÄ±p aÃ§manÄ±zÄ± isterse mutlaka yapÄ±n).*

### 2. Sistemi AyaÄŸa KaldÄ±rmak (Docker Compose)

TÃ¼m simÃ¼lasyon, test ortamÄ± ve yapay zeka altyapÄ±sÄ±nÄ± baÅŸlatmak iÃ§in:

```bash
docker compose up --build
```

Bu komut 3 adet konteyner ayaÄŸa kaldÄ±rÄ±r:
1. `sim`: UR5e, Gazebo, ROS2 ve MoveIt2.
2. `ollama`: Yerel yapay zeka motoru.
3. `testrunner`: Python ile yazÄ±lmÄ±ÅŸ test scriptlerini Ã§alÄ±ÅŸtÄ±racaÄŸÄ±nÄ±z izole alan.

---

## 3. DoÄŸrulama (Starter Kit Testleri)

Sistem ayaÄŸa kalktÄ±ktan sonra, projenin doÄŸru Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test etmek iÃ§in:

**A. UR5e Gazebo SimÃ¼lasyonunu AÃ§mak:**
```bash
# Host terminalinde X11 gÃ¶rÃ¼ntÃ¼ aktarÄ±mÄ±na izin ver:
xhost +local:docker

# SimÃ¼lasyonu baÅŸlat:
docker compose exec sim bash -c "ros2 launch ur_simulation_gazebo ur_sim_moveit.launch.py ur_type:=ur5e"
```

**B. Ollama LLM Testi:**
```bash
# Ollama'dan Llama3 (veya codellama) modelini Ã§ekin:
docker compose exec ollama ollama pull codellama:7b-code

# Modelin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± teyit edin:
curl -X POST http://localhost:11434/api/generate -d '{"model":"codellama:7b-code","prompt":"python hello world print"}'
```

---

## GeliÅŸtirme AkÄ±ÅŸÄ±

Projenizin kaynak kodlarÄ± (`src/`, `data/`) yerel bilgisayarÄ±nÄ±zdaki klasÃ¶rlerle **eÅŸzamanlÄ± (volume mapping)** olarak konteynerlere baÄŸlÄ±dÄ±r.
- KodlarÄ±nÄ±zÄ± kendi IDE'nizle (VS Code vb.) dÄ±ÅŸarÄ±da dÃ¼zenleyebilirsiniz.
- Ã‡alÄ±ÅŸtÄ±rmak iÃ§in `docker compose exec testrunner ...` komutlarÄ±nÄ± kullanabilirsiniz.
