"""
github_ros2_scraper.py â€” A4 ROS2 Fine-Tuning Data Collector
===========================================================
Bu script, Github API'sini kullanarak iÃ§inde 'rclpy', 'moveit', 'ur5e' gibi
ROS2 bileÅŸenleri geÃ§en Python scriptlerini tarar, indirir ve LLM eÄŸitimi
(Fine-Tuning) iÃ§in kullanÄ±labilecek 'Instruction-Response' formatÄ±nda bir
JSONL (JSON Lines) dosyasÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.

KullanÄ±m iÃ§in GITHUB_TOKEN ortam deÄŸiÅŸkeni gereklidir.
"""

import os
import json
import requests
import time
from typing import List, Dict
from dotenv import load_dotenv

# .env dosyasÄ±nÄ± yÃ¼kle (AynÄ± dizinde veya proje kÃ¶k dizininde arar)
load_dotenv()

# GitHub API rate limitlerini aÅŸmamak iÃ§in kiÅŸisel token
# .env veya terminal Ã¼zerinden GITHUB_TOKEN aranÄ±r
GITHUB_TOKEN = os.environ.get("GITHUB_TOKEN", "")

HEADERS = {
    "Accept": "application/vnd.github.v3+json",
}

if GITHUB_TOKEN:
    HEADERS["Authorization"] = f"token {GITHUB_TOKEN}"

# Arama sorgusu: Python dosyalarÄ±, iÃ§inde rclpy ve moveit geÃ§meli
# Not: GitHub Code Search API aramada 'stars' filtresini desteklemez.
# Kalite kontrolÃ¼ script iÃ§inde ayrÄ± API isteÄŸi ile yapÄ±lacaktÄ±r.
SEARCH_QUERY = "rclpy moveit language:python"

MIN_STARS = 5

def search_github_files(query: str, max_results: int = 100) -> List[Dict]:
    """GitHub API Ã¼zerinden belirtilen sorguya uygun dosyalarÄ± arar."""
    print(f"ğŸ” GitHub'da aranÄ±yor: '{query}'")
    items = []
    page = 1
    
    while len(items) < max_results:
        url = f"https://api.github.com/search/code?q={query}&per_page=100&page={page}"
        response = requests.get(url, headers=HEADERS)
        if response.status_code == 403:
            print("âŒ Hata: API Limitine ulaÅŸÄ±ldÄ± veya Token geÃ§ersiz!")
            if not GITHUB_TOKEN:
                print("   LÃ¼tfen GITHUB_TOKEN ortam deÄŸiÅŸkenini ayarlayÄ±n.")
            break
        elif response.status_code != 200:
            print(f"âŒ Hata: {response.status_code} - {response.text}")
            break
            
        data = response.json()
        new_items = data.get("items", [])
        if not new_items:
            break
            
        items.extend(new_items)
        print(f"âœ… Sayfa {page}: {len(new_items)} dosya bulundu. Toplam: {len(items)}")
        
        if len(new_items) < 100:
            break # Son sayfa veya limit
            
        page += 1
        time.sleep(2) # search api rate limitlerini yormamak iÃ§in kÄ±sa bekleme
        
    return items[:max_results]

def download_file_content(download_url: str) -> str:
    """GitHub dosyasÄ±nÄ±n raw iÃ§eriÄŸini indirir."""
    response = requests.get(download_url, headers=HEADERS)
    if response.status_code == 200:
        return response.text
    return ""

def check_repo_stars(repo_full_name: str, headers: Dict) -> int:
    """GitHub API Ã¼zerinden deponun gÃ¼ncel yÄ±ldÄ±z sayÄ±sÄ±nÄ± dÃ¶ndÃ¼rÃ¼r."""
    repo_url = f"https://api.github.com/repos/{repo_full_name}"
    resp = requests.get(repo_url, headers=headers)
    if resp.status_code == 200:
        return resp.json().get("stargazers_count", 0)
    return 0

def generate_instruction_for_code(code: str, filename: str) -> str:
    """
    GeÃ§ici olarak statik, ileride Gemini/Claude ile dinamik Ã¼retilecek
    Instruction (Soru) kÄ±smÄ±nÄ± oluÅŸturur.
    """
    return f"Write a ROS2 Python node named {filename} that uses rclpy and MoveIt2 for robotic manipulation."

def main():
    if not GITHUB_TOKEN:
        print("âš ï¸ DÄ°KKAT: GITHUB_TOKEN olmadan api limitiniz saatlik 60 istek ile sÄ±nÄ±rlÄ±dÄ±r.")
        
    output_file = "ros2_dataset.jsonl"
    results = search_github_files(SEARCH_QUERY, max_results=300)
    
    dataset = []
    
    print("â³ Dosyalar indiriliyor ve kontrol ediliyor...")
    for i, item in enumerate(results):
        print(f"[{i+1}/{len(results)}] Ä°ndiriliyor: {item['name']}")
        
        # Raw indirme linkini bul
        # Repositorie URL'sinden raw URL'sini parse edelim
        repo_name = item['repository']['full_name']
        file_path = item['path']
        
        # Repo yÄ±ldÄ±z sayÄ±sÄ±nÄ± kontrol et
        stars = check_repo_stars(repo_name, HEADERS)
        if stars < MIN_STARS:
            print(f"      [{stars} yÄ±ldÄ±z] {MIN_STARS} yÄ±ldÄ±zdan dÃ¼ÅŸÃ¼k = AtlanÄ±yor.")
            continue
        
        print(f"      â­ Repo kalitesi onaylandÄ±: {stars} yÄ±ldÄ±z")
        
        # API Ã¼zerinden iÃ§eriÄŸi Ã§ek (base64)
        content_url = item['url']
        content_resp = requests.get(content_url, headers=HEADERS)
        
        if content_resp.status_code == 200:
            import base64
            content_data = content_resp.json()
            if 'content' in content_data:
                code_content = base64.b64decode(content_data['content']).decode('utf-8', errors='ignore')
                
                # Kod Ã§ok kÄ±saysa (10 satÄ±rdan az) salla
                if len(code_content.splitlines()) < 10:
                    continue
                    
                instruction = generate_instruction_for_code(code_content, item['name'])
                
                # JSONL FormatÄ±: {"instruction": "...", "response": "..."}
                dataset.append({
                    "instruction": instruction,
                    "response": code_content
                })
        
        # API limitine takÄ±lmamak iÃ§in minik bekleme
        time.sleep(1)

    # JSONL'ye yaz (Eski veriler kaybolmasÄ±n diye 'a' append modu kullanÄ±lÄ±r)
    if dataset:
        with open(output_file, 'a', encoding='utf-8') as f:
            for entry in dataset:
                f.write(json.dumps(entry, ensure_ascii=False) + '\\n')
        print(f"\\nğŸ‰ BaÅŸarÄ±lÄ±! {len(dataset)} adet yeni Ã¶rnek {output_file} dosyasÄ±na EKLENDÄ° (Eskiler korundu).")
        print("ğŸ§  Bu veri seti Qwen2.5-Coder veya Llama modelini eÄŸitmek iÃ§in hazÄ±rdÄ±r!")
    else:
        print("\\nâš ï¸ HiÃ§ veri toplanamadÄ±.")

if __name__ == "__main__":
    main()
