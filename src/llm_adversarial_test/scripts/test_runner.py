"""
test_runner.py â€” A4 Adversarial Test Pipeline
==============================================
TDD GREEN AÅAMASI: test_test_runner.py'deki 7 testi geÃ§irmek iÃ§in yazÄ±ldÄ±.

Bu modÃ¼l, adversarial test pipeline'Ä±nÄ±n ana motorudur.
Åunu yapar:
  1. YAML'dan prompt'larÄ± yÃ¼kler
  2. Her prompt'u Ollama'ya gÃ¶nderir
  3. LLM'in Ã¼rettiÄŸi yanÄ±ttan Python kodunu Ã§Ä±karÄ±r
  4. Kodu safety_analyzer ile analiz eder
  5. SonuÃ§larÄ± CSV'ye yazar

KullanÄ±m:
  docker compose exec testrunner python /app/scripts/test_runner.py
"""
import csv
import os
import re
import sys
import yaml
import time
import argparse
import subprocess
from dotenv import load_dotenv

# .env dosyasÄ±ndaki deÄŸiÅŸkenleri yÃ¼kle
load_dotenv()

# safety_analyzer aynÄ± klasÃ¶rde
sys.path.insert(0, os.path.dirname(__file__))
from safety_analyzer import analyze_code

# Ollama kÃ¼tÃ¼phanesi â€” sadece gerÃ§ek koÅŸuda import edilir
try:
    import ollama
except ImportError:
    ollama = None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. YAML'dan Prompt YÃ¼kleme
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_prompts(yaml_path: str) -> list[dict]:
    """
    adversarial_prompts.yaml dosyasÄ±ndan tÃ¼m prompt'larÄ± oku.
    Her gÃ¶rev grubundaki (pose_prompts, waypoint_prompts, pick_place_prompts)
    prompt'larÄ± tek bir dÃ¼z listeye Ã§evirir.

    Returns:
        list[dict]: Her biri {id, task, category, risk_level, prompt} iÃ§eren dict listesi
    """
    with open(yaml_path, 'r') as f:
        data = yaml.safe_load(f)

    all_prompts = []
    # YAML'daki her anahtar (*_prompts) altÄ±ndaki listeyi topla
    for key, prompt_list in data.items():
        if key.endswith("_prompts") and isinstance(prompt_list, list):
            all_prompts.extend(prompt_list)

    return all_prompts


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. LLM YanÄ±tÄ±ndan Kod Ã‡Ä±karma
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extract_code_from_response(response: str) -> str:
    """
    LLM yanÄ±tÄ±ndan Python kod bloÄŸunu Ã§Ä±kar.

    LLM bazen ÅŸÃ¶yle yanÄ±t verir:
        Here is the code:
        ```python
        import rclpy
        ...
        ```

    Bu fonksiyon ```python ... ``` arasÄ±ndaki kodu Ã§Ä±karÄ±r.
    EÄŸer markdown bloÄŸu yoksa, ham yanÄ±tÄ± aynen dÃ¶ndÃ¼rÃ¼r.
    """
    if not response or not response.strip():
        return ""

    # ```python ... ``` veya ``` ... ``` arasÄ±nÄ± bul
    pattern = r"```(?:python)?\s*\n(.*?)```"
    matches = re.findall(pattern, response, re.DOTALL)

    if matches:
        # En uzun kod bloÄŸunu al (birden fazla olabilir)
        return max(matches, key=len).strip()

    # Markdown bloÄŸu yoksa â†’ ham metni dÃ¶ndÃ¼r
    return response.strip()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. Sandbox'ta Kod Ã‡alÄ±ÅŸtÄ±rma (Execution)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_in_sandbox(code: str, prompt_id: str, model_name: str) -> dict:
    """
    LLM'in Ã¼rettiÄŸi kodu fiziksel olarak kaydeder ve 'a4_sim' (ROS2) 
    konteynerinde Ã§alÄ±ÅŸtÄ±rÄ±r. Sonucu ve hatalarÄ± analiz iÃ§in dÃ¶ndÃ¼rÃ¼r.
    """
    if not code:
        return {"execution_success": False, "execution_msg": "No code generated."}
        
    safe_model_name = model_name.replace(":", "_").replace("-", "_")
    filename = f"{prompt_id}_{safe_model_name}.py"
    
    # 1. Kodu fiziksel olarak kaydet (veri klasÃ¶rÃ¼ne)
    scripts_dir = "/app/data/generated_scripts"
    os.makedirs(scripts_dir, exist_ok=True)
    filepath = os.path.join(scripts_dir, filename)
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(code)
        
    # 2. sim konteynerinde "data" klasÃ¶rÃ¼ "/ws/data" olarak mount edilmiÅŸ durumda.
    container_filepath = f"/ws/data/generated_scripts/{filename}"
    
    try:
        # 3. Kodu 30 saniye timeout ile ROS2 ortamÄ±nda Ã§alÄ±ÅŸtÄ±r
        result = subprocess.run(
            ["docker", "exec", "a4_sim", "python3", container_filepath],
            capture_output=True,
            text=True,
            timeout=30
        )
        
        if result.returncode == 0:
            return {"execution_success": True, "execution_msg": "Success (Exit 0)"}
        else:
            # Sadece hata mesajÄ±nÄ±n kritik (son 150) kÄ±smÄ±nÄ± al 
            # (csv satÄ±rlarÄ±nÄ± bozmamak iÃ§in)
            err = result.stderr.strip() if result.stderr else ""
            err_msg = err[-150:].replace("\n", " | ") if err else f"Exit code {result.returncode}"
            return {"execution_success": False, "execution_msg": f"Crash: {err_msg}"}
            
    except subprocess.TimeoutExpired:
        return {"execution_success": False, "execution_msg": "Timeout (Task took > 30s)"}
    except Exception as e:
        return {"execution_success": False, "execution_msg": f"Sandbox Error: {str(e)}"}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. Tek Bir Deney KoÅŸusu
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_single_experiment(prompt_data: dict, model: str = "dolphin-mistral:7b",
                          host: str = None) -> dict:
    """
    Tek bir prompt'u LLM'e gÃ¶nderip sonucu analiz eder.

    Args:
        prompt_data: {id, task, category, prompt, ...}
        model: Ollama model adÄ±
        host: Ollama sunucu adresi

    Returns:
        dict: {prompt_id, task, category, model, safety_score, checks..., raw_code}
    """
    if ollama is None:
        raise RuntimeError("ollama kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil")

    host = host or os.environ.get("OLLAMA_HOST", "http://127.0.0.1:11434")
    client = ollama.Client(host=host)

    # LLM'e prompt gÃ¶nder
    start_time = time.time()
    response = client.generate(
        model=model,
        prompt=prompt_data["prompt"],
        stream=False,
    )
    elapsed = round(time.time() - start_time, 2)

    # YanÄ±ttan kodu Ã§Ä±kar
    raw_response = response.response if hasattr(response, 'response') else response.get('response', '')
    code = extract_code_from_response(raw_response)

    # Kodu analiz et
    analysis = analyze_code(code)
    
    # Kodu SimÃ¼lasyon sandbox'Ä±nda Ã§alÄ±ÅŸtÄ±r (Execution Test)
    exec_result = run_in_sandbox(code, prompt_data["id"], model)

    return {
        "prompt_id": prompt_data["id"],
        "task": prompt_data["task"],
        "category": prompt_data.get("category", "unknown"),
        "risk_level": prompt_data.get("risk_level", "unknown"),
        "model": model,
        "safety_score": analysis["safety_score"],
        "uses_moveit2": analysis["checks"]["uses_moveit2"],
        "has_collision_checking": analysis["checks"]["has_collision_checking"],
        "has_velocity_limit": analysis["checks"]["has_velocity_limit"],
        "sends_direct_joint_cmd": analysis["checks"]["sends_direct_joint_cmd"],
        "execution_success": exec_result["execution_success"],
        "execution_msg": exec_result["execution_msg"],
        "summary": analysis["summary"],
        "response_time_sec": elapsed,
        "code_length": len(code),
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. CSV'ye Kaydetme
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def save_results_to_csv(results: list[dict], output_path: str):
    """
    SonuÃ§larÄ± CSV dosyasÄ±na yaz.
    Ä°lk satÄ±r baÅŸlÄ±k (header), sonraki satÄ±rlar veri.
    """
    if not results:
        return

    os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)

    fieldnames = list(results[0].keys())
    with open(output_path, 'w', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(results)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. Ana Ã‡alÄ±ÅŸtÄ±rma (CLI)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """
    TÃ¼m pipeline'Ä± Ã§alÄ±ÅŸtÄ±r:
    YAML oku â†’ Her prompt'u LLM'e gÃ¶nder â†’ Analiz et â†’ CSV'ye yaz
    """
    print("ğŸ§ª A4 Adversarial Test Pipeline")
    print("=" * 50)

    # 1. Prompt'larÄ± yÃ¼kle
    prompts_path = "/app/data/prompts/adversarial_prompts.yaml"
    prompts = load_prompts(prompts_path)
    print(f"ğŸ“‹ {len(prompts)} prompt yÃ¼klendi")

    # 2. ArgÃ¼man parsing (Model bilgisi)
    parser = argparse.ArgumentParser(description="A4 Adversarial Test Pipeline")
    parser.add_argument("--model", type=str, default=os.environ.get("LLM_MODEL", "dolphin-mistral:7b"),
                        help="KullanÄ±lacak Ollama modelinin adÄ± (Ã–rn: deepseek-coder:6.7b)")
    args = parser.parse_args()
    
    model = args.model
    print(f"ğŸ¤– Model: {model}")

    # 3. Her prompt'u Ã§alÄ±ÅŸtÄ±r
    results = []
    for i, prompt_data in enumerate(prompts, 1):
        print(f"\n[{i}/{len(prompts)}] {prompt_data['id']} ({prompt_data['category']})")
        try:
            result = run_single_experiment(prompt_data, model=model)
            results.append(result)
            print(f"  â†’ Skor: {result['safety_score']}/100 | {result['summary']}")
        except Exception as e:
            print(f"  âŒ Hata: {e}")
            results.append({
                "prompt_id": prompt_data["id"],
                "task": prompt_data["task"],
                "category": prompt_data.get("category", "unknown"),
                "risk_level": prompt_data.get("risk_level", "unknown"),
                "model": model,
                "safety_score": -1,
                "uses_moveit2": False,
                "has_collision_checking": False,
                "has_velocity_limit": False,
                "sends_direct_joint_cmd": False,
                "execution_success": False,
                "execution_msg": f"Pipeline Error: {e}",
                "summary": f"HATA: {e}",
                "response_time_sec": 0,
                "code_length": 0,
            })

    # 4. SonuÃ§larÄ± kaydet
    output_path = "/app/data/results/experiment_results.csv"
    save_results_to_csv(results, output_path)
    print(f"\nğŸ“Š SonuÃ§lar kaydedildi: {output_path}")
    print(f"âœ… {len(results)} deney tamamlandÄ±!")


if __name__ == "__main__":
    main()
