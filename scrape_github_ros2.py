#!/usr/bin/env python3
"""
A4 Projesi â€” GitHub'dan ROS2/MoveIt2 Python KodlarÄ± Scraper
============================================================
GitHub Code Search API kullanarak ROS2 robotik Python scriptlerini Ã§eker.
Tekrar eden dosyalarÄ± SHA hash ile filtreler.

KullanÄ±m:
    python3 scrape_github_ros2.py

Ã‡Ä±ktÄ±:
    ros2_dataset_v2.jsonl  (instruction + response formatÄ±nda)
"""

import os
import json
import time
import hashlib
import base64
import re
import sys
from pathlib import Path

try:
    import requests
except ImportError:
    print("âŒ 'requests' kÃ¼tÃ¼phanesi bulunamadÄ±. YÃ¼kleniyor...")
    os.system(f"{sys.executable} -m pip install requests")
    import requests

from dotenv import load_dotenv

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• CONFIG â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

load_dotenv()
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN", "")
if not GITHUB_TOKEN:
    print("âŒ GITHUB_TOKEN .env dosyasÄ±nda bulunamadÄ±!")
    sys.exit(1)

HEADERS = {
    "Authorization": f"Bearer {GITHUB_TOKEN}",
    "Accept": "application/vnd.github.v3+json",
    "X-GitHub-Api-Version": "2022-11-28",
}

OUTPUT_FILE = "ros2_dataset_v2.jsonl"
MIN_FILE_SIZE = 300       # byte â€” Ã§ok kÄ±sa snippet'leri atla
MAX_FILE_SIZE = 80_000    # byte â€” Ã§ok uzun dosyalarÄ± atla
MAX_RESULTS_PER_QUERY = 30  # GitHub API sayfa limiti (max 100, ama rate limit)
API_DELAY = 12            # GitHub code search: 10 req/min, gÃ¼venli aralÄ±k

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• KEYWORD GROUPS â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SEARCH_QUERIES = [
    # â”€â”€ GRUP 1: GÃ¼venli Kodlar (MoveIt2 ile planlama) â”€â”€
    {
        "query": "rclpy MoveIt2 move_to_pose language:python",
        "category": "safe",
        "desc": "MoveIt2 ile gÃ¼venli poz hedefi",
    },
    {
        "query": "rclpy moveit plan_kinematic_path language:python",
        "category": "safe",
        "desc": "MoveIt2 ile kinematik yol planlama",
    },
    {
        "query": "max_velocity_scaling_factor rclpy language:python",
        "category": "safe",
        "desc": "HÄ±z sÄ±nÄ±rlamasÄ± uygulayan ROS2 kodu",
    },
    {
        "query": "avoid_collisions MoveIt rclpy language:python",
        "category": "safe",
        "desc": "Ã‡arpÄ±ÅŸma kontrolÃ¼ iÃ§eren MoveIt kodu",
    },
    {
        "query": "MoveItPy planning_component language:python",
        "category": "safe",
        "desc": "MoveIt2 Python API ile planlama",
    },
    {
        "query": "pymoveit2 move_to_configuration language:python",
        "category": "safe",
        "desc": "pymoveit2 ile gÃ¼venli konfigÃ¼rasyon hareketi",
    },
    {
        "query": "collision_checking moveit rclpy language:python",
        "category": "safe",
        "desc": "Ã‡arpÄ±ÅŸma kontrolÃ¼ ile MoveIt kullanÄ±mÄ±",
    },

    # â”€â”€ GRUP 2: GÃ¼vensiz KalÄ±plar (GÃ¼venlik Ã¶nlemi eksik) â”€â”€
    {
        "query": "JointTrajectory publish rclpy language:python",
        "category": "unsafe_pattern",
        "desc": "MoveIt2 kullanmadan doÄŸrudan joint trajectory yayÄ±nlama",
    },
    {
        "query": "FollowJointTrajectory send_goal rclpy language:python",
        "category": "unsafe_pattern",
        "desc": "Planlama olmadan doÄŸrudan joint action komutu",
    },
    {
        "query": "JointTrajectoryPoint velocities rclpy language:python",
        "category": "unsafe_pattern",
        "desc": "Joint hÄ±z deÄŸerleri ile doÄŸrudan hareket komutu",
    },
    {
        "query": "joint_trajectory_controller rclpy language:python",
        "category": "unsafe_pattern",
        "desc": "ros2_control controller'a doÄŸrudan trajectory yazma",
    },
    {
        "query": "JointTrajectory points append rclpy language:python",
        "category": "unsafe_pattern",
        "desc": "PlansÄ±z trajectory oluÅŸturma",
    },
    {
        "query": "set_joint_value_target rclpy language:python",
        "category": "unsafe_pattern",
        "desc": "DoÄŸrudan joint deÄŸeri hedefleme",
    },

    # â”€â”€ GRUP 3: UR Robot Spesifik â”€â”€
    {
        "query": "ur5e joint_states rclpy language:python",
        "category": "ur_specific",
        "desc": "UR5e joint durumu okuma ve kontrol",
    },
    {
        "query": "ur_robot_driver rclpy language:python",
        "category": "ur_specific",
        "desc": "UR robot driver ile haberleÅŸme",
    },
    {
        "query": "universal_robots rclpy moveit language:python",
        "category": "ur_specific",
        "desc": "Universal Robots MoveIt entegrasyonu",
    },
    {
        "query": "ur_moveit_config rclpy language:python",
        "category": "ur_specific",
        "desc": "UR MoveIt konfigÃ¼rasyon kullanÄ±mÄ±",
    },
]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• DEDUPLICATION â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

seen_sha = set()           # GitHub file SHA
seen_content_hash = set()  # Ä°Ã§erik MD5 hash (farklÄ± repo ama aynÄ± kod)


def content_hash(text: str) -> str:
    """Normalize edip MD5 hash al â€” whitespace/comment farklarÄ± yoksay."""
    # BoÅŸluklarÄ± normalize et, yorumlarÄ± sil
    lines = []
    for line in text.splitlines():
        stripped = line.strip()
        if stripped and not stripped.startswith("#"):
            lines.append(stripped)
    normalized = "\n".join(lines)
    return hashlib.md5(normalized.encode()).hexdigest()


def is_duplicate(sha: str, code: str) -> bool:
    """SHA veya iÃ§erik hash'i ile tekrar kontrolÃ¼."""
    if sha in seen_sha:
        return True
    chash = content_hash(code)
    if chash in seen_content_hash:
        return True
    seen_sha.add(sha)
    seen_content_hash.add(chash)
    return False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• VALIDATION â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def is_valid_ros2_python(code: str) -> bool:
    """DosyanÄ±n gerÃ§ekten ROS2 Python kodu olup olmadÄ±ÄŸÄ±nÄ± kontrol et."""
    # En az birinden bahsetmeli
    ros2_indicators = [
        "rclpy", "Node", "ros2", "ROS2",
        "JointTrajectory", "moveit", "MoveIt",
        "joint_states", "sensor_msgs", "geometry_msgs",
        "trajectory_msgs", "control_msgs", "moveit_msgs",
    ]
    has_ros2 = any(ind in code for ind in ros2_indicators)
    has_python = "import " in code or "def " in code or "class " in code
    return has_ros2 and has_python


def generate_instruction(filename: str, category: str, desc: str) -> str:
    """Dosya adÄ± ve kategoriye gÃ¶re instruction metnini Ã¼ret."""
    safe_name = Path(filename).stem
    return f"Write a ROS2 Python node named {filename} that {desc}."


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• GITHUB API â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def search_github_code(query: str, per_page: int = 30) -> list:
    """GitHub Code Search API ile arama yap."""
    url = "https://api.github.com/search/code"
    params = {
        "q": query,
        "per_page": min(per_page, 100),
        "sort": "indexed",
        "order": "desc",
    }
    try:
        resp = requests.get(url, headers=HEADERS, params=params, timeout=30)
        if resp.status_code == 403:
            # Rate limit â€” bekle
            reset_time = int(resp.headers.get("X-RateLimit-Reset", 0))
            wait = max(reset_time - int(time.time()), 60)
            print(f"  â³ Rate limit! {wait}s bekleniyor...")
            time.sleep(wait + 1)
            return search_github_code(query, per_page)
        if resp.status_code == 422:
            print(f"  âš ï¸  GeÃ§ersiz query: {query}")
            return []
        resp.raise_for_status()
        return resp.json().get("items", [])
    except requests.exceptions.RequestException as e:
        print(f"  âŒ API hatasÄ±: {e}")
        return []


def fetch_file_content(url: str) -> str | None:
    """Dosya iÃ§eriÄŸini GitHub Contents API ile Ã§ek."""
    try:
        resp = requests.get(url, headers=HEADERS, timeout=30)
        if resp.status_code != 200:
            return None
        data = resp.json()
        if data.get("encoding") == "base64" and data.get("content"):
            return base64.b64decode(data["content"]).decode("utf-8", errors="replace")
        return None
    except Exception:
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• MAIN â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    print("â•" * 60)
    print("  A4 Projesi â€” GitHub ROS2/MoveIt2 Code Scraper")
    print("â•" * 60)
    print(f"  Token: ...{GITHUB_TOKEN[-8:]}")
    print(f"  Toplam query sayÄ±sÄ±: {len(SEARCH_QUERIES)}")
    print(f"  Ã‡Ä±ktÄ±: {OUTPUT_FILE}")
    print("â•" * 60)

    results = []  # list of {instruction, response}
    stats = {"safe": 0, "unsafe_pattern": 0, "ur_specific": 0, "skipped_dup": 0, "skipped_invalid": 0, "skipped_size": 0}

    for i, sq in enumerate(SEARCH_QUERIES, 1):
        query = sq["query"]
        category = sq["category"]
        desc = sq["desc"]

        print(f"\n[{i}/{len(SEARCH_QUERIES)}] ğŸ” {query}")
        print(f"  Kategori: {category} | AÃ§Ä±klama: {desc}")

        items = search_github_code(query, MAX_RESULTS_PER_QUERY)
        print(f"  Bulunan: {len(items)} dosya")

        for item in items:
            sha = item.get("sha", "")
            filename = item.get("name", "unknown.py")
            file_url = item.get("url", "")  # Contents API URL
            repo_name = item.get("repository", {}).get("full_name", "unknown")

            if not filename.endswith(".py"):
                continue

            # Dosya iÃ§eriÄŸini Ã§ek
            code = fetch_file_content(file_url)
            if code is None:
                continue

            # Boyut kontrolÃ¼
            code_bytes = len(code.encode("utf-8"))
            if code_bytes < MIN_FILE_SIZE or code_bytes > MAX_FILE_SIZE:
                stats["skipped_size"] += 1
                continue

            # Tekrar kontrolÃ¼
            if is_duplicate(sha, code):
                stats["skipped_dup"] += 1
                continue

            # ROS2 Python kontrolÃ¼
            if not is_valid_ros2_python(code):
                stats["skipped_invalid"] += 1
                continue

            # Instruction Ã¼ret
            instruction = generate_instruction(filename, category, desc)

            entry = {
                "instruction": instruction,
                "response": code,
            }
            results.append(entry)
            stats[category] += 1

            print(f"    âœ“ {repo_name}/{filename} ({code_bytes}B)")

            # API rate limit korumasÄ± (dosya Ã§ekme)
            time.sleep(0.5)

        # Code Search rate limit: 10 req/min
        if i < len(SEARCH_QUERIES):
            print(f"  â³ API rate limit bekleniyor ({API_DELAY}s)...")
            time.sleep(API_DELAY)

    # â•â•â• KAYDET â•â•â•
    print("\n" + "â•" * 60)
    print("  SONUÃ‡LAR")
    print("â•" * 60)

    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        for entry in results:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")

    print(f"  âœ… GÃ¼venli kodlar: {stats['safe']}")
    print(f"  âš ï¸  GÃ¼vensiz kalÄ±p: {stats['unsafe_pattern']}")
    print(f"  ğŸ¤– UR spesifik:   {stats['ur_specific']}")
    print(f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"  ğŸ“Š TOPLAM: {len(results)} satÄ±r â†’ {OUTPUT_FILE}")
    print(f"  ğŸ”„ Tekrar atlandÄ±: {stats['skipped_dup']}")
    print(f"  âŒ GeÃ§ersiz atlandÄ±: {stats['skipped_invalid']}")
    print(f"  ğŸ“ Boyut atlandÄ±: {stats['skipped_size']}")
    print("â•" * 60)

    # JSON validasyonu
    print("\nğŸ” JSON Validasyonu...")
    try:
        with open(OUTPUT_FILE, "r") as f:
            for line_no, line in enumerate(f, 1):
                json.loads(line)
        print(f"  âœ… {line_no} satÄ±rÄ±n tamamÄ± geÃ§erli JSON!")
    except json.JSONDecodeError as e:
        print(f"  âŒ SatÄ±r {line_no}: {e}")


if __name__ == "__main__":
    main()
